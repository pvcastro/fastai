{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *        # Quick access to most common functionality\n",
    "from fastai.text import *   # Quick access to NLP functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of creating a language model and then transfering to a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/discoD/fastai/data/wiki/pt')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/media/discoD/fastai/data/wiki/pt')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/discoD/fastai/data/wiki/pt/tmp/itos.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-85b2466e840c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'itos.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/discoD/fastai/data/wiki/pt/tmp/itos.pkl'"
     ]
    }
   ],
   "source": [
    "itos = pickle.load(open(path/'tmp'/'itos.pkl', 'rb'))\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/media/discoD/Corpora/Anexos Trabalhistas/200kk')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/media/discoD/Corpora/Anexos Trabalhistas/200kk')\n",
    "#path = Path('/media/discoD/fastai/data/wiki/pt')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load(open(path/'tmp'/'itos.pkl', 'rb'))\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(path/'tmp'/'train_ids.npy')\n",
    "tok_tst = np.load(path/'tmp'/'test_ids.npy')\n",
    "tok_val = np.load(path/'tmp'/'valid_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xxup', 22962801),\n",
       " (',', 16808634),\n",
       " ('de', 10960125),\n",
       " ('.', 8879642),\n",
       " ('a', 7597534),\n",
       " ('\\n', 7336655),\n",
       " ('do', 6920493),\n",
       " ('o', 5706833),\n",
       " ('-', 5387489),\n",
       " ('\\n ', 4825104),\n",
       " ('da', 4761271),\n",
       " (')', 4482108),\n",
       " ('que', 3660299),\n",
       " ('e', 3565020),\n",
       " (':', 3070489),\n",
       " ('xxunk', 2622662),\n",
       " ('trabalho', 2586286),\n",
       " ('/', 2522491),\n",
       " ('se', 2392844),\n",
       " ('em', 2374612),\n",
       " ('(', 1666518),\n",
       " ('os', 1625193),\n",
       " ('não', 1587663),\n",
       " ('no', 1577188),\n",
       " ('para', 1405769)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(itos[term], count) for (term, count) in freq.most_common(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_id_files(path=path, train='train', valid='valid', test='test', max_vocab=60000,\n",
    "                                        min_freq=2, n_labels=0, chunksize=24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lm = TextLMDataBunch.from_csv(path=path, tokenizer=Tokenizer(lang='pt'), train='train', valid='val', \n",
    "#                                   max_vocab=60000, min_freq=2, n_labels=0, chunksize=24000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open and view the independent and dependent variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `DataBunch` for each of the language model and the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lm = TextLMDataBunch.from_csv(path)\n",
    "#data_clas = TextClasDataBunch.from_csv(path, vocab=data_lm.train_ds.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[fast.ai](http://www.fast.ai/) has a pre-trained English model available that we can download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.download_wt103_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune the language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b6f57c77ab49f1812b6d68de092480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=2), HTML(value='0.00% [0/2 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:18\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      4.931205    4.158325    0.244630  (00:09)\n",
      "1      4.660501    4.097024    0.252083  (00:09)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = RNNLearner.language_model(data_lm, pretrained_fnames=['lstm_wt103', 'itos_wt103'])\n",
    "learn.unfreeze()\n",
    "learn.fit(2, slice(1e-4,1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our language model's encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine tune it to create a classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78731ade5fa4345aaaed243bea56801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=3), HTML(value='0.00% [0/3 00:00<00:00]'))), HTML(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:21\n",
      "epoch  train loss  valid loss  accuracy\n",
      "0      0.709290    0.672736    0.610000  (00:07)\n",
      "1      0.685293    0.647017    0.630000  (00:06)\n",
      "2      0.662346    0.609948    0.660000  (00:07)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn = RNNLearner.classifier(data_clas)\n",
    "learn.load_encoder('enc')\n",
    "learn.fit(3, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
